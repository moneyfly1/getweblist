import time
import random
import sys
from typing import Optional

from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import NoSuchElementException
from tqdm import tqdm

from services.utils.toolbox.toolbox import get_ctx
from services.sspanel_mining.exceptions import CollectorSwitchError
from services.utils.proxy_manager import ProxyManager

class SSPanelHostsCollector:
    def __init__(
            self,
            path_file_txt: str,
            silence: bool = True,
            debug: bool = False,
    ):
        """

        :param path_file_txt:
        :param silence:
        :param debug:
        """
        # ç­›é€‰ Malio ç«™ç‚¹
        self._QUERY = "ç”± @editXY ä¿®æ”¹é€‚é…ã€‚"

        # å…¨é‡æœé›†
        # self._QUERY = 'inurl:staff "SSPanel V3 Mod UIM"'

        # éšæœºé€‰æ‹©ä¸åŒçš„æœç´¢æŸ¥è¯¢ï¼Œå‡å°‘è¢«æ£€æµ‹çš„å¯èƒ½æ€§
        search_queries = [
            "ç”± @editXY ä¿®æ”¹é€‚é…ã€‚",
            'inurl:staff "SSPanel V3 Mod UIM"',
            "SSPanel V3 Mod UIM",
            "SSPanel UIM",
            "SSPanel é¢æ¿"
        ]
        self._QUERY = random.choice(search_queries)

        self.GOOGLE_SEARCH_API = f'https://www.google.com.hk/search?q="{self._QUERY}"&filter=0'
        self.path_file_txt = path_file_txt
        self.debug = debug
        self.silence = silence
        self.page_num = 1
        
        # åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨
        self.proxy_manager = ProxyManager()
        self.current_proxy = None

    @staticmethod
    def _down_to_api(api, search_query: str):
        """æ£€ç´¢å…³é”®è¯å¹¶è·³è½¬è‡³ç›¸å…³é¡µé¢"""
        while True:
            try:
                input_tag = api.find_element(By.XPATH, "//input[@name='q']")
                try:
                    input_tag.click()
                # æ— å¤´æ¨¡å¼è¿è¡Œä¼šå¼•å‘é”™è¯¯
                except ElementClickInterceptedException:
                    pass
                input_tag.clear()
                input_tag.send_keys(search_query)
                input_tag.send_keys(Keys.ENTER)
                break

            except NoSuchElementException:
                time.sleep(0.5)
                continue

    @staticmethod
    def _page_switcher(api, is_home_page: bool = False):
        start_time = time.time()
        # é¦–é¡µ -> ç¬¬äºŒé¡µ
        if is_home_page:
            while True:
                try:
                    # éšæœºæ»šåŠ¨è¡Œä¸º
                    scroll_actions = [
                        lambda: ActionChains(api).send_keys(Keys.PAGE_DOWN).perform(),
                        lambda: ActionChains(api).send_keys(Keys.END).perform(),
                    ]
                    random.choice(scroll_actions)()
                    
                    time.sleep(random.uniform(0.5, 1.0))
                    api.find_element(By.XPATH, "//a[@id='pnnext']").click()
                    break
                except NoSuchElementException:
                    # æ£€æµ‹åˆ°åˆ°æµé‡æ‹¦æˆª ä¸»åŠ¨æŠ›å‡ºå¼‚å¸¸å¹¶é‡‡å–å¤‡ç”¨æ–¹æ¡ˆ
                    if "sorry" in api.current_url:
                        raise CollectorSwitchError
                    time.sleep(random.uniform(0.5, 1.0))
                    api.refresh()
                    continue
        # ç¬¬äºŒé¡µ -> ç¬¬Né¡µ
        else:
            while True:
                try:
                    # éšæœºæ»šåŠ¨è¡Œä¸º
                    scroll_actions = [
                        lambda: ActionChains(api).send_keys(Keys.PAGE_DOWN).perform(),
                        lambda: ActionChains(api).send_keys(Keys.END).perform(),
                    ]
                    random.choice(scroll_actions)()
                    
                    time.sleep(random.uniform(0.5, 1.0))
                    page_switchers = api.find_elements(By.XPATH, "//a[@id='pnnext']")
                    next_page_bottom = page_switchers[-1]
                    next_page_bottom.click()
                    break
                except (NoSuchElementException, IndexError):
                    time.sleep(random.uniform(0.5, 1.0))
                    # æ£€æµ‹åˆ°åˆ°æµé‡æ‹¦æˆª ä¸»åŠ¨æŠ›å‡ºå¼‚å¸¸å¹¶é‡‡å–å¤‡ç”¨æ–¹æ¡ˆ
                    if "sorry" in api.current_url:
                        raise CollectorSwitchError
                    # æœ€åä¸€é¡µ
                    if time.time() - start_time > 5:
                        break
                    continue

    def _page_tracking(self, api, ignore_filter=True):
        next_obj = None
        start_time = time.time()
        
        # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
        time.sleep(random.uniform(1, 3))
        
        while True:
            try:
                # éšæœºæ»šåŠ¨é¡µé¢ï¼Œæ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º
                scroll_actions = [
                    lambda: ActionChains(api).send_keys(Keys.PAGE_DOWN).perform(),
                    lambda: ActionChains(api).send_keys(Keys.END).perform(),
                    lambda: ActionChains(api).send_keys(Keys.PAGE_UP).perform(),
                ]
                random.choice(scroll_actions)()
                
                time.sleep(random.uniform(0.5, 1.5))
                next_obj = api.find_element(By.XPATH, "//a[@id='pnnext']")
                break
            except NoSuchElementException:
                time.sleep(random.uniform(0.5, 1.0))
                # æ£€æµ‹åˆ°åˆ°æµé‡æ‹¦æˆª ä¸»åŠ¨æŠ›å‡ºå¼‚å¸¸å¹¶é‡‡å–å¤‡ç”¨æ–¹æ¡ˆ
                if "sorry" in api.current_url:
                    # windowsè°ƒè¯•ç¯å¢ƒä¸­ï¼Œæ‰‹åŠ¨è§£å†³ CAPTCHA
                    if 'win' in sys.platform and not self.silence:
                        input("\n--> é­é‡æ‹¦æˆªï¼Œæœ¬å¼€æºä»£ç æœªæä¾›ç›¸åº”è§£å†³æ–¹æ¡ˆã€‚\n"
                              "--> è¯·å¼€å‘è€…æ‰‹åŠ¨å¤„ç† reCAPTCHA å¹¶äºæ§åˆ¶å°è¾“å…¥ä»»æ„é”®ç»§ç»­æ‰§è¡Œç¨‹åº\n"
                              f">>>")
                        continue
                    raise CollectorSwitchError
                # æœ€åä¸€é¡µ
                if time.time() - start_time > 5:
                    break
                continue

        if next_obj:
            next_url = next_obj.get_attribute("href")
            if ignore_filter:
                next_url = next_url + "&filter=0"
            
            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»ç‚¹å‡»è¡Œä¸º
            time.sleep(random.uniform(1, 2))
            api.get(next_url)
            return True
        else:
            return False

    def _capture_host(self, api):
        # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»é˜…è¯»æ—¶é—´
        time.sleep(random.uniform(2, 5))
        
        # éšæœºæ»šåŠ¨é¡µé¢
        scroll_actions = [
            lambda: ActionChains(api).send_keys(Keys.PAGE_DOWN).perform(),
            lambda: ActionChains(api).send_keys(Keys.END).perform(),
            lambda: ActionChains(api).send_keys(Keys.PAGE_UP).perform(),
            lambda: ActionChains(api).send_keys(Keys.HOME).perform(),
        ]
        random.choice(scroll_actions)()
        
        # å†æ¬¡éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(1, 3))
        
        hosts = api.find_elements(
            By.XPATH,
            "//div[contains(@class,'NJjxre')]//cite[@class='iUh30 qLRx3b tjvcx']"
        )

        with open(self.path_file_txt, "a", encoding="utf8") as f:
            for host in hosts:
                f.write(f"{host.text.split(' ')[0].strip()}/auth/register\n")

    def reset_page_num(self, api):
        try:
            result = api.find_element(By.XPATH, "//div[@id='result-stats']")
            tag_num = result.text.strip().split(" ")[1]
            self.page_num = int(int(tag_num) / 10) + 1 if tag_num else 26
            return self.page_num
        except NoSuchElementException:
            return None

    @staticmethod
    def set_loop_progress(total: int):
        return tqdm(
            total=total,
            desc="SSPanel COLLECTOR",
            ncols=150,
            unit="piece",
            dynamic_ncols=False,
            leave=True,
        )

    def reset_loop_progress(self, api, new_status: str = None):
        page_num_result = self.reset_page_num(api=api)
        if page_num_result is not None:
            self.page_num = page_num_result
        loop_progress = self.set_loop_progress(self.page_num)
        if new_status is not None:
            loop_progress.set_postfix({"status": new_status})

    def run(self, page_num: int = None, sleep_node: int = 5):
        """

        :param page_num: æœŸæœ›é‡‡é›†æ•°é‡
        :param sleep_node: ä¼‘çœ é—´éš”
        :return:
        """
        self.page_num = 26 if page_num is None else page_num

        loop_progress = self.set_loop_progress(self.page_num)
        loop_progress.set_postfix({"status": "__initialize__"})

        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # è·å–æ–°ä»£ç†
                if self.current_proxy:
                    self.proxy_manager.mark_proxy_failed(self.current_proxy)
                
                self.current_proxy = self.proxy_manager.get_proxy()
                if self.current_proxy:
                    self.proxy_manager.set_proxy_environment(self.current_proxy)
                    print(f"ä½¿ç”¨ä»£ç†: {self.current_proxy}")
                else:
                    print("è­¦å‘Š: æ²¡æœ‰å¯ç”¨ä»£ç†ï¼Œå°†ä½¿ç”¨ç›´è¿")
                
                with get_ctx(silence=self.silence) as ctx:
                    ctx.get(self.GOOGLE_SEARCH_API)
                    self.reset_loop_progress(api=ctx, new_status="__pending__")

                    # è·å–page_numé¡µçš„æ³¨å†Œé“¾æ¥
                    # æ­£å¸¸æƒ…å†µä¸€é¡µ10ä¸ªé“¾æ¥ æ—¢å…±è·å–page_num * 10ä¸ªé“¾æ¥
                    ack_num = 0
                    while True:
                        ack_num += 1
                        """
                        [ğŸ›´]é‡‡é›†å™¨
                        ___________
                        èƒå–æ³¨å†Œé“¾æ¥å¹¶ä¿å­˜
                        """
                        self._capture_host(api=ctx)
                        loop_progress.update(1)
                        loop_progress.set_postfix({"status": "__collect__"})

                        """
                        [ğŸ›´]ç¿»é¡µæ§åˆ¶å™¨
                        ___________
                        é¡µé¢è¿½è¸ª
                        """
                        try:
                            res = self._page_tracking(api=ctx)
                            if ack_num >= self.page_num:
                                self.reset_loop_progress(api=ctx, new_status="__reset__")
                                loop_progress.update(ack_num)
                            if not res:
                                # æ ‡è®°ä»£ç†æˆåŠŸ
                                if self.current_proxy:
                                    self.proxy_manager.mark_proxy_success(self.current_proxy)
                                return
                        except CollectorSwitchError:
                            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚é‡è¯•æœºåˆ¶å¤„ç†
                            raise

                        """
                        [ğŸ›´]ä¼‘çœ æ§åˆ¶å™¨
                        ___________
                        æ¯sleep_nodeé¡µè¿›è¡Œä¸€æ¬¡éšæœºæ—¶é•¿çš„ä¼‘çœ 
                        """
                        if ack_num % sleep_node == 0:
                            tax_ = random.uniform(3, 5)
                            loop_progress.set_postfix({"status": "__sleep__"})
                            time.sleep(tax_)
                            
                # å¦‚æœæˆåŠŸå®Œæˆï¼Œæ ‡è®°ä»£ç†æˆåŠŸå¹¶è·³å‡ºé‡è¯•å¾ªç¯
                if self.current_proxy:
                    self.proxy_manager.mark_proxy_success(self.current_proxy)
                break
                
            except CollectorSwitchError as e:
                retry_count += 1
                if retry_count < max_retries:
                    print(f"\n[WARNING] æ£€æµ‹åˆ°Googleæ‹¦æˆªï¼Œæ­£åœ¨è¿›è¡Œç¬¬{retry_count}æ¬¡é‡è¯•...")
                    print(f"[INFO] ç­‰å¾…{retry_count * 30}ç§’åé‡è¯•...")
                    time.sleep(retry_count * 30)  # é€’å¢ç­‰å¾…æ—¶é—´
                    
                    # é‡ç½®è¿›åº¦æ¡
                    loop_progress = self.set_loop_progress(self.page_num)
                    loop_progress.set_postfix({"status": f"__retry_{retry_count}__"})
                else:
                    print(f"\n[ERROR] ç»è¿‡{max_retries}æ¬¡é‡è¯•åä»ç„¶è¢«Googleæ‹¦æˆª")
                    print("[INFO] å»ºè®®ï¼š")
                    print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                    print("2. ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•")
                    print("3. è€ƒè™‘ä½¿ç”¨ä»£ç†æˆ–VPN")
                    print("4. åœ¨Windowsç¯å¢ƒä¸‹å¯ä»¥æ‰‹åŠ¨å¤„ç†éªŒè¯ç ")
                    print("5. è¿è¡Œä»£ç†æœé›†å™¨è·å–æ›´å¤šä»£ç†")
                    raise e
